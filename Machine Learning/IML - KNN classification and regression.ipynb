{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn is a non parametric algo that uses the target info from the k nearest neighbours of an observation and regress/classify based on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width          species\n",
       "30            4.8          3.1           1.6          0.2      Iris-setosa\n",
       "120           6.9          3.2           5.7          2.3   Iris-virginica\n",
       "72            6.3          2.5           4.9          1.5  Iris-versicolor\n",
       "122           7.7          2.8           6.7          2.0   Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0   Iris-virginica\n",
       "139           6.9          3.1           5.4          2.1   Iris-virginica\n",
       "67            5.8          2.7           4.1          1.0  Iris-versicolor\n",
       "66            5.6          3.0           4.5          1.5  Iris-versicolor\n",
       "74            6.4          2.9           4.3          1.3  Iris-versicolor\n",
       "118           7.7          2.6           6.9          2.3   Iris-virginica"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/satish/Downloads\")\n",
    "#Reading the data\n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Datsun 200-SX</td>\n",
       "      <td>23.9</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2405</td>\n",
       "      <td>14.9</td>\n",
       "      <td>78</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Peugeot 304</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>70</td>\n",
       "      <td>2074</td>\n",
       "      <td>19.5</td>\n",
       "      <td>71</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Saab 900s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2800</td>\n",
       "      <td>15.4</td>\n",
       "      <td>81</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Dodge Charger 2.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2370</td>\n",
       "      <td>13.0</td>\n",
       "      <td>82</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Oldsmobile Cutlass Salon Brougham</td>\n",
       "      <td>19.9</td>\n",
       "      <td>8</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3365</td>\n",
       "      <td>15.5</td>\n",
       "      <td>78</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Volkswagen Rabbit l</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1980</td>\n",
       "      <td>15.3</td>\n",
       "      <td>82</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Ford F108</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3870</td>\n",
       "      <td>15.0</td>\n",
       "      <td>76</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buick Skylark 320</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Toyota Corolla</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2228</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Plymouth Valiant</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>3121</td>\n",
       "      <td>16.5</td>\n",
       "      <td>73</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Car   MPG  Cylinders  Displacement  \\\n",
       "280                      Datsun 200-SX  23.9          4         119.0   \n",
       "58                         Peugeot 304  30.0          4          79.0   \n",
       "367                          Saab 900s   0.0          4         121.0   \n",
       "399                  Dodge Charger 2.2  36.0          4         135.0   \n",
       "256  Oldsmobile Cutlass Salon Brougham  19.9          8         260.0   \n",
       "383                Volkswagen Rabbit l  36.0          4         105.0   \n",
       "221                          Ford F108  13.0          8         302.0   \n",
       "1                    Buick Skylark 320  15.0          8         350.0   \n",
       "37                      Toyota Corolla  25.0          4         113.0   \n",
       "104                   Plymouth Valiant  18.0          6         225.0   \n",
       "\n",
       "     Horsepower  Weight  Acceleration  Model  Origin  \n",
       "280          97    2405          14.9     78   Japan  \n",
       "58           70    2074          19.5     71  Europe  \n",
       "367         110    2800          15.4     81  Europe  \n",
       "399          84    2370          13.0     82      US  \n",
       "256         110    3365          15.5     78      US  \n",
       "383          74    1980          15.3     82  Europe  \n",
       "221         130    3870          15.0     76      US  \n",
       "1           165    3693          11.5     70      US  \n",
       "37           95    2228          14.0     71   Japan  \n",
       "104         105    3121          16.5     73      US  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv(\"cars.csv\")\n",
    "cars.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all data points in df\n",
    "def standardize(df):\n",
    "    return (df - df.mean())/df.std()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find euclidean distance between data points of two series \n",
    "def euclidean(x, y):\n",
    "    d = np.sqrt(sum((x-y)**2))\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find root mean squared error\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cars data regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test for predictors and target\n",
    "\n",
    "split_df = cars.sample(len(cars))\n",
    "    \n",
    "train = split_df.iloc[0:300, : ]\n",
    "test  = split_df.iloc[300:406, : ]\n",
    "predictors = ['Weight', 'Horsepower', 'Displacement', 'Acceleration']\n",
    "target = ['MPG']\n",
    "X_train = train[predictors]\n",
    "Y_train = train[target]\n",
    "X_test = test[predictors]\n",
    "Y_test = test[target]\n",
    "\n",
    "# standardize feature set \n",
    "X_train = standardize(X_train)\n",
    "X_test = standardize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y_train))\n",
    "print(type(X_train.iloc[1,]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1nn algo\n",
    "def onennRegression(X_train, X_test, Y_train):\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(0, len(X_test)):\n",
    "        dist = []\n",
    "        # find euclidean distance of each test point from all train points\n",
    "        for j in range(0, len(X_train)):\n",
    "            d = euclidean(X_train.iloc[j,], X_test.iloc[i,])\n",
    "            dist.append(d)\n",
    "        \n",
    "        # find point in train with minimum distance from test \n",
    "        predicted.append(Y_train.iloc[dist.index(min(dist)), 0])\n",
    "    \n",
    "    \n",
    "    X_test['predicted_mpg'] = predicted\n",
    "    print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Weight  Horsepower  Displacement  Acceleration  predicted_mpg\n",
      "364 -0.403191   -0.104936     -0.676019     -0.174342           23.0\n",
      "6    1.654674    2.693357      2.343343     -2.335345           14.0\n",
      "84  -0.526261   -0.664595     -0.657993      1.017935           28.0\n",
      "174 -0.928604   -0.687914     -0.874306      0.272762           28.0\n",
      "150 -0.775950   -0.617956     -0.874306     -0.286118           30.9\n",
      "..        ...         ...           ...           ...            ...\n",
      "379 -0.509694   -0.478042     -0.531811      0.272762           26.6\n",
      "305  1.117428    0.478042      1.405989      0.794383           26.6\n",
      "403 -0.781867   -0.478042     -0.531811     -1.366620           36.0\n",
      "85   0.027552   -0.408084     -0.667006      1.576815           24.3\n",
      "316 -0.960554   -0.664595     -0.865293     -0.211601           32.2\n",
      "\n",
      "[106 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "onennRegression(X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.805511369737462\n",
      "Target range:  0.0 to 41.5\n"
     ]
    }
   ],
   "source": [
    "# find rmse \n",
    "\n",
    "print(\"RMSE: \",rmse(X_test[\"predicted_mpg\"], Y_test[\"MPG\"]))\n",
    "print(\"Target range: \",Y_test[\"MPG\"].min(), \"to\", Y_test[\"MPG\"].max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test for predictors and target\n",
    "split_df = cars.sample(len(cars))\n",
    "    \n",
    "train = split_df.iloc[0:300, : ]\n",
    "test  = split_df.iloc[300:406, : ]\n",
    "predictors = ['Weight', 'Horsepower', 'Displacement', 'Acceleration']\n",
    "target = ['MPG']\n",
    "X_train = train[predictors]\n",
    "Y_train = train[target]\n",
    "X_test = test[predictors]\n",
    "Y_test = test[target]\n",
    "\n",
    "# standardize feature set \n",
    "X_train = standardize(X_train)\n",
    "X_test = standardize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn algo\n",
    "def knnRegression(X_train, X_test,Y_train, k):\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(0, len(X_test)):\n",
    "        dist = []\n",
    "        # find euclidean distance of each test point from all train points\n",
    "        for j in range(0, len(X_train)):\n",
    "            d = euclidean(X_train.iloc[j,], X_test.iloc[i,])\n",
    "            dist.append(d)\n",
    "        \n",
    "        # Smallest K elements indices\n",
    "        # using sorted() + lambda + list slicing\n",
    "        indices = sorted(range(len(dist)), key = lambda ind: dist[ind])[:k]\n",
    "        \n",
    "        # find mean of k nearest neighbours of test point\n",
    "        predicted.append(Y_train.iloc[indices, 0].mean())\n",
    "        \n",
    "        \n",
    "    X_test['predicted_mpg'] = predicted\n",
    "    print(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Weight  Horsepower  Displacement  Acceleration  predicted_mpg\n",
      "341 -0.698731   -0.106480     -1.192797     -1.111916      22.166667\n",
      "279 -0.202084   -0.459932     -0.419631      0.631418      24.100000\n",
      "266  0.043385   -0.459932      0.048087      0.323771      20.133333\n",
      "113  1.674900    1.778597      1.479876     -1.111916      14.166667\n",
      "16   0.658771    1.307328      1.384423     -2.650152      10.000000\n",
      "..        ...         ...           ...           ...            ...\n",
      "225 -1.378053   -1.096146     -1.106890      0.973249      34.700000\n",
      "301 -1.206795   -0.931201     -1.040073     -0.188974      31.833333\n",
      "198  0.229485   -0.106480      0.286718     -0.120608      18.666667\n",
      "270  0.471529    1.425145      0.343990     -0.804268      16.066667\n",
      "180 -0.556016   -0.177171     -0.725080      0.426320      25.000000\n",
      "\n",
      "[106 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "knnRegression(X_train, X_test,Y_train,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.085787117837952\n",
      "Target range:  0.0 to 44.6\n"
     ]
    }
   ],
   "source": [
    "# find rmse \n",
    "\n",
    "print(\"RMSE: \",rmse(X_test[\"predicted_mpg\"], Y_test[\"MPG\"]))\n",
    "print(\"Target range: \",Y_test[\"MPG\"].min(), \"to\", Y_test[\"MPG\"].max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that from 1nn and knn we get rmse of around 5 which is good for range 0 to 44 and knn has better performance than 1nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test for predictors and target\n",
    "split_df = iris.sample(len(iris))\n",
    "    \n",
    "train = split_df.iloc[0:100, : ]\n",
    "test  = split_df.iloc[100:150, : ]\n",
    "predictors = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "target = ['species']\n",
    "X_train = train[predictors]\n",
    "Y_train = train[target]\n",
    "X_test = test[predictors]\n",
    "Y_test = test[target]     \n",
    "    \n",
    "# standardize feature set \n",
    "X_train = standardize(X_train)\n",
    "X_test = standardize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 nn algo\n",
    "def onennClassification(X_train, X_test,Y_train):\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(0, len(X_test)):\n",
    "        dist = []\n",
    "        for j in range(0, len(X_train)):\n",
    "            # find euclidean distance of test point from all train points\n",
    "            d = euclidean(X_train.iloc[j,], X_test.iloc[i,])\n",
    "            dist.append(d)\n",
    "        \n",
    "        # use class of point in train with minimum distance\n",
    "        predicted.append(Y_train.iloc[dist.index(min(dist)), 0])\n",
    "    \n",
    "    \n",
    "    X_test['predicted_species'] = predicted\n",
    "    print(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width predicted_species\n",
      "44      -0.812379     1.547079     -0.980945    -0.943020       Iris-setosa\n",
      "115      0.778122     0.264969      0.946924     1.573466    Iris-virginica\n",
      "4       -0.934725     1.119709     -1.264455    -1.207913       Iris-setosa\n",
      "116      0.900468    -0.162401      1.060328     0.911233    Iris-virginica\n",
      "98      -0.812379    -1.230825     -0.357223    -0.015894   Iris-versicolor\n",
      "86       1.145161     0.051284      0.606711     0.513893   Iris-versicolor\n",
      "133      0.655776    -0.589770      0.833520     0.513893    Iris-virginica\n",
      "30      -1.179418     0.051284     -1.151051    -1.207913       Iris-setosa\n",
      "27      -0.690033     0.906024     -1.207753    -1.207913       Iris-setosa\n",
      "13      -1.791149    -0.162401     -1.434561    -1.340360       Iris-setosa\n",
      "88      -0.200648    -0.162401      0.266499     0.249000   Iris-versicolor\n",
      "33      -0.322994     2.401819     -1.264455    -1.207913       Iris-setosa\n",
      "9       -1.057071     0.051284     -1.207753    -1.340360       Iris-setosa\n",
      "60      -0.934725    -2.299250     -0.073713    -0.148340   Iris-versicolor\n",
      "58       1.022814    -0.376085      0.550009     0.249000   Iris-versicolor\n",
      "74       0.778122    -0.376085      0.379903     0.249000   Iris-versicolor\n",
      "39      -0.812379     0.692339     -1.207753    -1.207913       Iris-setosa\n",
      "40      -0.934725     0.906024     -1.321157    -1.075466       Iris-setosa\n",
      "76       1.267507    -0.589770      0.663413     0.381446   Iris-versicolor\n",
      "51       0.778122     0.264969      0.493307     0.513893   Iris-versicolor\n",
      "77       1.145161    -0.162401      0.776817     0.778786    Iris-virginica\n",
      "126      0.533430    -0.589770      0.663413     0.911233    Iris-virginica\n",
      "63       0.411083    -0.376085      0.606711     0.381446   Iris-versicolor\n",
      "29      -1.301764     0.264969     -1.151051    -1.207913       Iris-setosa\n",
      "62       0.288737    -1.871880      0.209797    -0.148340   Iris-versicolor\n",
      "134      0.411083    -1.017140      1.117030     0.381446   Iris-versicolor\n",
      "32      -0.690033     2.188134     -1.207753    -1.340360       Iris-setosa\n",
      "121     -0.200648    -0.589770      0.720115     1.176126    Iris-virginica\n",
      "57      -1.057071    -1.444510     -0.187117    -0.148340   Iris-versicolor\n",
      "36      -0.322994     0.906024     -1.321157    -1.207913       Iris-setosa\n",
      "107      1.879238    -0.376085      1.513944     0.911233    Iris-virginica\n",
      "11      -1.179418     0.692339     -1.151051    -1.207913       Iris-setosa\n",
      "147      0.900468    -0.162401      0.890222     1.176126    Iris-virginica\n",
      "14       0.044045     1.974449     -1.377859    -1.207913       Iris-setosa\n",
      "21      -0.812379     1.333394     -1.207753    -0.943020       Iris-setosa\n",
      "109      1.756892     1.119709      1.400540     1.838359    Iris-virginica\n",
      "55      -0.078302    -0.589770      0.493307     0.249000   Iris-versicolor\n",
      "83       0.288737    -0.803455      0.833520     0.646339    Iris-virginica\n",
      "106     -1.057071    -1.230825      0.493307     0.778786   Iris-versicolor\n",
      "101      0.044045    -0.803455      0.833520     1.043679    Iris-virginica\n",
      "80      -0.322994    -1.444510      0.096393    -0.015894   Iris-versicolor\n",
      "66      -0.200648    -0.162401      0.493307     0.513893    Iris-virginica\n",
      "67       0.044045    -0.803455      0.266499    -0.148340   Iris-versicolor\n",
      "120      1.389853     0.264969      1.173732     1.573466    Iris-virginica\n",
      "24      -1.179418     0.692339     -0.980945    -1.207913       Iris-setosa\n",
      "26      -0.934725     0.692339     -1.151051    -0.943020       Iris-setosa\n",
      "112      1.267507    -0.162401      1.060328     1.308572    Iris-virginica\n",
      "6       -1.424110     0.692339     -1.264455    -1.075466       Iris-setosa\n",
      "118      2.368623    -1.017140      1.854156     1.573466    Iris-virginica\n",
      "124      1.145161     0.478654      1.173732     1.308572    Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "onennClassification(X_train, X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy of the model\n",
    "(X_test[\"predicted_species\"] == Y_test[\"species\"]).sum()/len(Y_test[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test for predictors and target\n",
    "split_df = iris.sample(len(iris))\n",
    "    \n",
    "train = split_df.iloc[0:100, : ]\n",
    "test  = split_df.iloc[100:150, : ]\n",
    "predictors = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "target = ['species']\n",
    "X_train = train[predictors]\n",
    "Y_train = train[target]\n",
    "X_test = test[predictors]\n",
    "Y_test = test[target]     \n",
    "    \n",
    "# standardize feature set \n",
    "X_train = standardize(X_train)\n",
    "X_test = standardize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn algo\n",
    "def knnClassification(X_train, X_test,Y_train, k):\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(0, len(X_test)):\n",
    "        dist = []\n",
    "        for j in range(0, len(X_train)):\n",
    "            # find euclidean distance of each test point from all train points\n",
    "            d = euclidean(X_train.iloc[j,], X_test.iloc[i,])\n",
    "            dist.append(d)\n",
    "        \n",
    "        \n",
    "        # Smallest K elements indices\n",
    "        # using sorted() + lambda + list slicing\n",
    "        # use majority of class in k nearest points in train data\n",
    "        indices = sorted(range(len(dist)), key = lambda sub: dist[sub])[:k]\n",
    "        predicted.append(Y_train.iloc[indices,0].value_counts().idxmax())\n",
    "    \n",
    "    \n",
    "    X_test['predicted_species'] = predicted\n",
    "    print(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length   petal_width predicted_species\n",
      "65       1.046508    -0.057369      0.490603  3.798767e-01   Iris-versicolor\n",
      "145      1.046508    -0.318139      0.926695  1.519507e+00    Iris-virginica\n",
      "102      1.513700    -0.318139      1.308275  1.266256e+00    Iris-virginica\n",
      "80      -0.355065    -1.882756      0.163534 -2.811652e-16   Iris-versicolor\n",
      "74       0.696115    -0.578908      0.436092  2.532511e-01   Iris-versicolor\n",
      "117      2.214487     1.768018      1.744366  1.392881e+00    Iris-virginica\n",
      "31      -0.471863     0.724939     -1.090229 -8.863789e-01       Iris-setosa\n",
      "34      -1.055852    -0.057369     -1.090229 -1.266256e+00       Iris-setosa\n",
      "72       0.579317    -1.621987      0.763160  5.065022e-01    Iris-virginica\n",
      "52       1.280104    -0.057369      0.763160  5.065022e-01   Iris-versicolor\n",
      "130      1.864093    -0.839678      1.417298  1.013004e+00    Iris-virginica\n",
      "97       0.462519    -0.578908      0.436092  2.532511e-01   Iris-versicolor\n",
      "116      0.812913    -0.318139      1.090229  8.863789e-01    Iris-virginica\n",
      "58       0.929711    -0.578908      0.599626  2.532511e-01   Iris-versicolor\n",
      "29      -1.289448     0.203400     -1.035717 -1.139630e+00       Iris-setosa\n",
      "26      -0.939054     0.724939     -1.035717 -8.863789e-01       Iris-setosa\n",
      "45      -1.172650    -0.318139     -1.144740 -1.013004e+00       Iris-setosa\n",
      "103      0.579317    -0.578908      1.144740  8.863789e-01    Iris-virginica\n",
      "38      -1.639841    -0.318139     -1.199252 -1.139630e+00       Iris-setosa\n",
      "54       0.812913    -0.839678      0.599626  5.065022e-01    Iris-virginica\n",
      "19      -0.822257     1.768018     -1.090229 -1.013004e+00       Iris-setosa\n",
      "120      1.280104     0.203400      1.199252  1.519507e+00    Iris-virginica\n",
      "84      -0.471863    -0.318139      0.545114  5.065022e-01   Iris-versicolor\n",
      "112      1.163306    -0.318139      1.090229  1.266256e+00    Iris-virginica\n",
      "91       0.345722    -0.318139      0.599626  3.798767e-01   Iris-versicolor\n",
      "36      -0.355065     0.985709     -1.199252 -1.139630e+00       Iris-setosa\n",
      "85       0.228924     0.724939      0.545114  6.331278e-01   Iris-versicolor\n",
      "47      -1.406246     0.203400     -1.144740 -1.139630e+00       Iris-setosa\n",
      "5       -0.471863     2.028787     -0.981206 -8.863789e-01       Iris-setosa\n",
      "33      -0.355065     2.811096     -1.144740 -1.139630e+00       Iris-setosa\n",
      "139      1.280104    -0.057369      1.035717  1.266256e+00    Iris-virginica\n",
      "11      -1.172650     0.724939     -1.035717 -1.139630e+00       Iris-setosa\n",
      "40      -0.939054     0.985709     -1.199252 -1.013004e+00       Iris-setosa\n",
      "143      1.163306     0.203400      1.308275  1.519507e+00    Iris-virginica\n",
      "37      -1.055852    -0.057369     -1.090229 -1.266256e+00       Iris-setosa\n",
      "51       0.696115     0.203400      0.545114  5.065022e-01   Iris-versicolor\n",
      "53      -0.355065    -2.143526      0.272557  2.532511e-01   Iris-versicolor\n",
      "113     -0.121470    -1.621987      0.817672  1.139630e+00    Iris-virginica\n",
      "1       -1.055852    -0.318139     -1.144740 -1.139630e+00       Iris-setosa\n",
      "111      0.696115    -1.100448      0.981206  1.013004e+00    Iris-virginica\n",
      "43      -0.939054     0.985709     -1.035717 -6.331278e-01       Iris-setosa\n",
      "39      -0.822257     0.724939     -1.090229 -1.139630e+00       Iris-setosa\n",
      "30      -1.172650    -0.057369     -1.035717 -1.139630e+00       Iris-setosa\n",
      "101     -0.004672    -1.100448      0.872183  1.013004e+00    Iris-virginica\n",
      "42      -1.639841     0.203400     -1.199252 -1.139630e+00       Iris-setosa\n",
      "96      -0.121470    -0.578908      0.381580  2.532511e-01   Iris-versicolor\n",
      "48      -0.588661     1.507248     -1.090229 -1.139630e+00       Iris-setosa\n",
      "79      -0.121470    -1.361217      0.000000 -1.266256e-01   Iris-versicolor\n",
      "17      -0.822257     0.985709     -1.144740 -1.013004e+00       Iris-setosa\n",
      "140      1.046508    -0.057369      1.144740  1.646132e+00    Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "knnClassification(X_train, X_test,Y_train,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy of the model\n",
    "(X_test[\"predicted_species\"] == Y_test[\"species\"]).sum()/len(Y_test[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see that the accuracy of knn classifier is 0.96 while that of 1nn classifier is 0.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
